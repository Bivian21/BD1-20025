'use strict';self.ScreenRec=function(){function t(a){let f={width:1280,height:720},n=0,k=b.micId;b.realStream=a;return navigator.mediaDevices.enumerateDevices().then(function(d){let e={stream:a,closeStreamCallback:void 0,resolution:f,hasAudio:!1!==k,hasSystemAudio:!1};d.forEach(function(c){"audioinput"===c.kind&&n++});let p=Utils.delay(500).then(function(){a.getVideoTracks().forEach(function(c){e.streamFrom=c.getSettings().displaySurface;e.streamFrom||(Utils.isChromium()?e.streamFrom="browser":e.streamFrom=
""===c.label?"monitor":"window");f.width=c.getSettings().width;f.height=c.getSettings().height;console.log("User selected track type: "+e.streamFrom+" orig: "+f.width+"x"+f.height)});b.set("waitingForSetup",!1);return e});return k?0===n?(console.log("No mics found so just using screenStream."),p):navigator.mediaDevices.getUserMedia({audio:{deviceId:{exact:k}}}).then(function(c){let l=new MediaStream;a.getVideoTracks().forEach(function(h){l.addTrack(h)});if(0<a.getAudioTracks().length){e.hasSystemAudio=
!0;q.listen("closeStream",()=>{console.log("Closing audio track from system/tab.");a.getAudioTracks().forEach(m=>m.stop());c.getAudioTracks().forEach(m=>m.stop())});var g=new AudioContext;let h=g.createMediaStreamDestination();var r=g.createMediaStreamSource(a);const u=g.createGain();u.gain.value=1;r.connect(u).connect(h);console.log("added system audio");c&&0<c.getAudioTracks().length&&(r=g.createMediaStreamSource(c),g=g.createGain(),g.gain.value=1,r.connect(g).connect(h),console.log("added mic audio"));
h.stream.getAudioTracks().forEach(function(m){l.addTrack(m)})}else c.getAudioTracks().forEach(function(h){l.addTrack(h)});console.log("CompossedStream ready.");e.stream=l;b.realStream=l;return p}).catch(function(c){console.error("getUserMedia failed: "+c);Utils.stopStream(a);b.set("waitingForSetup",!1);throw c;}):(console.log("Top parent has setup NOT to use audio so just using screenStream."),0<a.getAudioTracks().length&&(e.hasAudio=!0),p)}).catch(function(d){console.error("enumerateDevices failed: "+
d);Utils.stopStream(a);b.set("waitingForSetup",!1);throw d;})}let b={micId:void 0};const q=OffscreenProxy.for("ScreenRec").connect(b);b.start=function(a,f,n,k){b.set("waitingForSetup",!0);b.micId=f;if(a&&"tabCapture"===a.source)return navigator.mediaDevices.getUserMedia({audio:{mandatory:{chromeMediaSource:"tab",chromeMediaSourceId:a.tabMediaId}},video:{optional:[],mandatory:{chromeMediaSource:"tab",chromeMediaSourceId:a.tabMediaId,maxWidth:a.tabMaxSize.width,maxHeight:a.tabMaxSize.height,minFrameRate:20,
maxFrameRate:30}}}).then(function(d){console.log("getUserMedia after getMediaStreamId success for tabCapture");const e=new AudioContext;e.createMediaStreamSource(d).connect(e.destination);return t(d)}).catch(function(d){console.error("getUserMedia after getMediaStreamId failed for tabCapture: "+d)});a=void 0;"undefined"!==typeof window&&n&&"CaptureController"in window&&"setFocusBehavior"in CaptureController.prototype&&(a=new CaptureController,a.setFocusBehavior("no-focus-change"));return navigator.mediaDevices.getDisplayMedia({audio:!0,
video:k?k:!0,controller:a}).then(t).catch(function(d){console.error("getDisplayMedia failed: "+d);b.set("waitingForSetup",!1);throw d;})};b.onStreamEnd=function(a){b.realStream.getTracks().forEach(function(f){f.onended=()=>{a&&(a(),a=void 0)}})};b.getOffscreenStream=()=>b.realStream;q.listen("start",a=>b.start(a.type,a.micId,a.noFocus,a.noTypeVideoConstraints));q.listen("onStreamEnd",a=>{b.onStreamEnd(a.callback)});return b}();